{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import pyautogui\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å\n",
    "root = tk.Tk()\n",
    "root.attributes(\"-topmost\", True)  # ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏™‡∏∏‡∏î\n",
    "root.overrideredirect(True)  # ‡πÄ‡∏≠‡∏≤‡∏Ç‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å (Borderless)\n",
    "root.geometry(\"1400x100+271+865\")  # ‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á (‡∏Å‡∏ß‡πâ‡∏≤‡∏á x ‡∏™‡∏π‡∏á + ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á X + ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Y)\n",
    "root.configure(bg=\"black\")  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™\n",
    "# root.wm_attributes(\"-transparentcolor\", \"black\")\n",
    "# ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á\n",
    "text_label = tk.Label(root, text=\"üåü ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° Overlay üåü\", font=(\"tahoma\", 24), fg=\"white\", bg=\"black\")\n",
    "text_label.pack(expand=True)\n",
    "\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏≤‡∏Å‡πÑ‡∏î‡πâ\n",
    "def move_window(event):\n",
    "    root.geometry(f\"+{event.x_root}+{event.y_root}\")\n",
    "    print(event.x_root, event.y_root)\n",
    "\n",
    "# ‡∏à‡∏±‡∏ö event ‡∏Å‡∏≤‡∏£‡∏•‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á\n",
    "text_label.bind(\"<B1-Motion>\", move_window)\n",
    "\n",
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mss\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "with mss.mss() as sct:\n",
    "    monitor = {\"top\": 970, \"left\": 200, \"width\": 1400, \"height\": 180}\n",
    "    screenshot = sct.grab(monitor)\n",
    "\n",
    "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô OpenCV\n",
    "    img = np.array(screenshot)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "    # ‡πÅ‡∏™‡∏î‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ\n",
    "    cv2.imshow(\"Captured Region\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "translate sub ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "import pytesseract\n",
    "import mss\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from PIL import Image, ImageTk\n",
    "import keyboard\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á Tesseract OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤\n",
    "TRANSLATE_API_URL = \"http://localhost:8000/translate\"  # ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ Google Translate API\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å\n",
    "root = tk.Tk()\n",
    "root.attributes(\"-topmost\", True)  # ‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏™‡∏∏‡∏î\n",
    "root.overrideredirect(True)  # ‡πÄ‡∏≠‡∏≤‡∏Ç‡∏≠‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å (Borderless)\n",
    "root.geometry(\"1400x100+271+813\")  # ‡∏Ç‡∏ô‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á (‡∏Å‡∏ß‡πâ‡∏≤‡∏á x ‡∏™‡∏π‡∏á + ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á X + ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Y)\n",
    "root.configure(bg=\"black\")  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÇ‡∏õ‡∏£‡πà‡∏á‡πÉ‡∏™\n",
    "root.wm_attributes(\"-transparentcolor\", \"black\")\n",
    "\n",
    "# ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á\n",
    "translated_text = tk.StringVar()\n",
    "\n",
    "text_label = tk.Label(root, textvariable=translated_text, font=(\"tahoma\", 20), fg=\"white\", bg=\"black\")\n",
    "text_label.pack(expand=True)\n",
    "\n",
    "def enhance_image(img):\n",
    "    \"\"\"‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏£‡∏≤‡∏™‡∏ï‡πå‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏†‡∏≤‡∏û‡∏Ñ‡∏°‡∏ä‡∏±‡∏î‡∏Ç‡∏∂‡πâ‡∏ô\"\"\"\n",
    "    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏£‡∏≤‡∏™‡∏ï‡πå\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = cv2.equalizeHist(l)  # ‡∏õ‡∏£‡∏±‡∏ö histogram\n",
    "    lab = cv2.merge([l, a, b])\n",
    "    img = cv2.cvtColor(lab, cv2.COLOR_Lab2BGR)\n",
    "\n",
    "    # ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏†‡∏≤‡∏û‡∏Ñ‡∏°‡∏ä‡∏±‡∏î\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]])  # Kernel ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sharpening\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "    # ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏á\n",
    "    img = cv2.convertScaleAbs(img, alpha=1.5, beta=0)\n",
    "    return img\n",
    "\n",
    "def preprocess_image(img):\n",
    "    \"\"\"‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô\"\"\"\n",
    "    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô grayscale\n",
    "    # ‡πÉ‡∏ä‡πâ Otsu thresholding ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô binary\n",
    "    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return img\n",
    "\n",
    "\n",
    "def capture_screen():\n",
    "    with mss.mss() as sct:\n",
    "        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ (‡πÅ‡∏Å‡πâ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ã‡∏±‡∏ö‡πÄ‡∏Å‡∏°)\n",
    "        monitor = {\"top\": 900, \"left\": 200, \"width\": 1400, \"height\": 200}\n",
    "        screenshot = sct.grab(monitor)\n",
    "\n",
    "        # ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô OpenCV\n",
    "        img = np.array(screenshot)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY)  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≤‡∏ß‡∏î‡∏≥\n",
    "        img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]  # ‡πÄ‡∏û‡∏¥‡πà‡∏° contrast\n",
    "        \n",
    "        # ‡πÉ‡∏ä‡πâ OCR ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "        text = pytesseract.image_to_string(img, lang=\"eng\")  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô \"eng\" ‡πÄ‡∏õ‡πá‡∏ô \"tha\" ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
    "        return text.strip()\n",
    "\n",
    "def translate_text(text):\n",
    "    \"\"\"‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á API ‡πÅ‡∏õ‡∏•‡∏†‡∏≤‡∏©‡∏≤\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    data = {\"text\": text, \"to\": \"th\"}  # ‡πÅ‡∏õ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
    "    response = requests.post(TRANSLATE_API_URL, json=data)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get(\"translatedText\", \"‡πÅ‡∏õ‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ\")\n",
    "    return \"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î\"\n",
    "    \n",
    "\n",
    "def update_subtitles():\n",
    "    \"\"\"‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏ã‡∏±‡∏ö‡πÑ‡∏ï‡πÄ‡∏ï‡∏¥‡∏•‡πÄ‡∏Å‡∏°‡πÅ‡∏ö‡∏ö Realtime\"\"\"\n",
    "    text = capture_screen()\n",
    "    if text:     \n",
    "        translated_text.set(translate_text(text))  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡πÅ‡∏•‡πâ‡∏ß\n",
    "    root.after(250, update_subtitles)  # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏ó‡∏∏‡∏Å 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°\n",
    "def close_program(event=None):\n",
    "    root.destroy()\n",
    "\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡πâ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏≤‡∏Å‡πÑ‡∏î‡πâ\n",
    "def move_window(event):\n",
    "    root.geometry(f\"+{event.x_root}+{event.y_root}\")\n",
    "    print(event.x_root, event.y_root)\n",
    "\n",
    "# ‡∏à‡∏±‡∏ö event ‡∏Å‡∏≤‡∏£‡∏•‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á\n",
    "text_label.bind(\"<B1-Motion>\", move_window)\n",
    "\n",
    "# ‡∏à‡∏±‡∏ö‡∏õ‡∏∏‡πà‡∏° F1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°\n",
    "keyboard.add_hotkey('F1', close_program)\n",
    "\n",
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•\n",
    "update_subtitles()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sound read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏°‡∏Ñ‡πå (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô index ‡∏ï‡∏≤‡∏°‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)\n",
    "mic_index = 1  # ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô 1, 2, ... ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô\n",
    "\n",
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "recognizer = sr.Recognizer()\n",
    "with sr.Microphone(device_index=mic_index) as source:\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=2)  # ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô\n",
    "    print(\"üé§ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ü‡∏±‡∏á... ‡∏û‡∏π‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡∏≤‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á!\")\n",
    "    while True:\n",
    "        try:\n",
    "            audio = recognizer.listen(source, timeout=5, phrase_time_limit=8)\n",
    "            text = recognizer.recognize_google(audio)\n",
    "            print(f\"üìù ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ: {text}\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"‚ùå ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏¢‡∏¥‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î!\")\n",
    "        except sr.RequestError:\n",
    "            print(\"‚ö†Ô∏è ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Google Speech API\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "device_count = p.get_device_count()\n",
    "\n",
    "for i in range(device_count):\n",
    "    device_info = p.get_device_info_by_index(i)\n",
    "    print(f\"Device {i}: {device_info['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
